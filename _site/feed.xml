<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.2.1">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2017-06-25T22:06:40-07:00</updated><id>/</id><title>Vikas Mohandoss</title><subtitle>Student at Columbia University</subtitle><entry><title>NewsLetter_1</title><link href="/NewsLetter1/" rel="alternate" type="text/html" title="NewsLetter_1" /><published>2017-06-25T00:00:00-07:00</published><updated>2017-06-25T00:00:00-07:00</updated><id>/NewsLetter1</id><content type="html" xml:base="/NewsLetter1/">&lt;p&gt;So, as I feel sorry for wasting resources on Github, I’m starting a newsletter about important topics that I have read/are in queue to read and spiel I’d like to share. It will help serve as my dashboard, that is accessible on all devices and hopefully is useful to at least 1 more person.&lt;/p&gt;

&lt;p&gt;June-July 2017&lt;/p&gt;

&lt;p&gt;NewsLetter&lt;/p&gt;

&lt;p&gt;AI -&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Yaov Goldberg and Yann LeCunn’s popcorn consuming take on ArXiv and the publicity(false?) of neural nets - https://medium.com/@yoav.goldberg/an-adversarial-review-of-adversarial-generation-of-natural-language-409ac3378bd7, https://www.facebook.com/yann.lecun/posts/10154498539442143, https://medium.com/@yoav.goldberg/a-response-to-yann-lecuns-response-245125295c02&lt;/li&gt;
  &lt;li&gt;SELU Activation Function that helps self normalize neural nets - https://arxiv.org/pdf/1706.02515.pdf. Fun Note : One of the authors - Hochreiter published a paper on LSTM in 1997. (I really do not know my target audience, so forgive me)&lt;/li&gt;
  &lt;li&gt;All developers calling, Google’s in-house object detection system is now open sourced. Yes! until of course free trial runs out… I miss the old days when I could build local models and feel smug about accuracy. (And, I didn’t have to pay!)&lt;/li&gt;
  &lt;li&gt;Neural Network inception by Christopher Google Nolan
https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html&lt;/li&gt;
  &lt;li&gt;Speaking of neural nets, there is now one to rule the world. - https://arxiv.org/pdf/1706.05137.pdf
I wish there were more details in the paper. Deep Learning papers are always so obscure. (Are they written by neural nets?)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Systems -&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Chandler Carruth is a funny guy. Loved his video on Algorithms for efficiency and data structures for performance - https://www.youtube.com/watch?v=fHNmRkzxHWs&amp;amp;t=3586s, compiler&lt;/li&gt;
  &lt;li&gt;Another Chandler Carruth video on compiler optimization - https://www.youtube.com/watch?v=FnGCDLhaxKU&lt;/li&gt;
  &lt;li&gt;A look into Google’s TPU - https://cloud.google.com/blog/big-data/2017/05/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu&lt;/li&gt;
  &lt;li&gt;Mike Acton on data oriented design. Haven’t seen it yet but have heard excellent reviews - https://www.youtube.com/watch?v=rX0ItVEVjHc&lt;/li&gt;
  &lt;li&gt;Also currently reading a book - Parallel Computing for data science by Norman Matloff. Highly recommend it thus far. (Will touch upon this again on completion).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In a land far far away -&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Elon Musk’s plan to conquer Mars - http://online.liebertpub.com/doi/pdf/10.1089/space.2017.29009.emu&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Personal -&lt;/p&gt;

&lt;p&gt;LinkedLists are so bad! Never use them if you care about performance.
They mess up cache access. Simple Stat - 3B cycles per second on one of my processors(Wow!), 50% of that time is on I/O (Damn!). Efficient Algorithms -&amp;gt; Better data structures -&amp;gt; Better caching -&amp;gt; Faster data access from memory -&amp;gt; Happy Life, unless of course you can afford clusters in which case, please ignore this. Debugging performance bottlenecks is hard. Machine Learning is hard.&lt;/p&gt;

&lt;p&gt;Took part in the T-mobil Big Data hackathon (March 2017) and made an application that automatically tags photos and uploads to Instagram based on object detection and location features. I love solving laziness. Now, only if I can get myself to use social media and upload these damn pictures so they can get tagged. - https://www.youtube.com/watch?v=qEaGuX18sz4&amp;amp;t=27s&lt;/p&gt;

&lt;p&gt;Took part in AI++ Weekend (April 2017) and made an anomaly detection system that checks for trends in mixture of data sources and reports if the end user has anything to be worried/excited about. This project was harder than I first thought. Someone, please donate some cloud credits.&lt;/p&gt;

&lt;p&gt;Took part in Global AI Hackathon (June 2017) and made a music player that receives live video feed from camera input and detects the surrounding environment to choose the right song to play from spotify. It then gauges audience engagement and perception and changes songs accordingly. I really need to address the infrastructure to process frames as we had some performance lag. Also, excited to start training the model to see what it does! - https://www.youtube.com/watch?v=-kjTLG0EA5E&amp;amp;feature=youtu.be&lt;/p&gt;

&lt;p&gt;Suggestions to improve on features will be nice :). I will open source the code, once I clean up.&lt;/p&gt;

&lt;p&gt;Visited NYC, Miami, Orlando, Los Angeles and San Jose in the space of 3 weeks courtesy of graduation ceremony at Columbia University (I am apparently a Master now with my degree), a guide to the United States for my parents and other family reasons.&lt;/p&gt;

&lt;p&gt;Random thought of the day –&lt;/p&gt;

&lt;p&gt;Data really is the new oil. When do/did the wars begin?&lt;/p&gt;</content><summary>So, as I feel sorry for wasting resources on Github, I’m starting a newsletter about important topics that I have read/are in queue to read and spiel I’d like to share. It will help serve as my dashboard, that is accessible on all devices and hopefully is useful to at least 1 more person.</summary></entry><entry><title>Machine Learning - Is it for you ?</title><link href="/MLIntro/" rel="alternate" type="text/html" title="Machine Learning - Is it for you ?" /><published>2016-09-29T00:00:00-07:00</published><updated>2016-09-29T00:00:00-07:00</updated><id>/MLIntro</id><content type="html" xml:base="/MLIntro/">&lt;p&gt;In this post, I will at a high level describe this field and answer some of these questions -&lt;/p&gt;

&lt;p&gt;What is Machine Learning ?
What are the prerequisites to learn this subject ?
What are the career opportunities in this field ?
What are the latest trends in Machine Learning ?&lt;/p&gt;

&lt;p&gt;To start, let me begin by saying that Machine Learning is not new. It has existed in various shapes and forms for a long time and work in this field is being simultaneously pushed forward by those researchers in signal processing,computer science,statistics,neuroscience and many other departments. At its bare minimal level, Machine Learning asks the question, given the data that I have, can I collect information that is useful to process future data. This is the fundamental difference with data analytics which asks the fundamental question, given the data that I have, can I collect information that is useful for me right now to describe it and take intelligible action. Of course, both areas of work are more similar than they are different as without understanding the data right now, it would not be easy to process future data.&lt;/p&gt;

&lt;p&gt;To dive in a bit deeper, as you would have guessed by now, machine learning deals with a lot of data. A very simple machine learning problem would be, given some data, learn enough about it to understand the model, then use that model to predict future data. To start learning this subject, it would be advisable to have a basic background in linear algebra, probability theory, calculus, and programming in Matlab and Python/R. Why? Lets find out.&lt;/p&gt;

&lt;p&gt;Linear Algebra - Representation and transformation of data. Any input data has many fields to it like an excel spreadsheet with multiple columns. This data is represented as a matrix and to learn the model, we would do some algebra with this matrix. Thus the importance of linear algebra.&lt;/p&gt;

&lt;p&gt;Calculus - Given the data, we want the best model to predict future data. Sounds familiar? It is a maximization problem. In machine learning, we often deal with min/max problems and knowledge of Calculus is essential.&lt;/p&gt;

&lt;p&gt;Probability - Many times while predicting data, we may not want to predict as a single answer as very rarely can we predict with 100% certainty. Rather, a softer approach would be to represent results as probability of multiple events and herein is the importance of concepts such as expectations and probability theory.&lt;/p&gt;

&lt;p&gt;Programming - Given all the theory about matrices and transformations, it is a little tedious to use complicated data structures in traditional languages such as C++. Matlab readily ingests data as matrices and is great for linear algebra and hence very easy to prototype machine learning models. In addition, It is useful to know to code in 1 scripting language such as python as it supports scientific programming with libraries such as numpy,sklearn,theano and provides an interface for traditional programming to create applications.&lt;/p&gt;

&lt;p&gt;Know that these concepts can be picked up on the go or may not be needed at all if the intention is to apply machine learning to applications. However, for a career in research or graduate school in machine learning, it is advantageous to be strong with these fundamentals beforehand.&lt;/p&gt;

&lt;p&gt;The Andrew NG course on Coursera (https://www.coursera.org/learn/machine-learning) is a very famous starter module. Another resource that I have found very useful is the Scikit documentation (http://scikit-learn.org/stable/documentation.html). They cover almost all algorithms and you can choose to understand at a deeper level from the internet based on your interest and also implement it very easily and see results. A highly recommended programming platform that I use for scientific computing is Jupyter Notebook. It is fantastic. (http://jupyter.org/)&lt;/p&gt;

&lt;p&gt;In terms of career opportunities, there are many different roles available depending on your balance between quantitative and programming skills. Assuming knowledge of machine learning, some roles include&lt;/p&gt;

&lt;p&gt;Strong Quant+Strong Programming - Quant Analyst/Data Scientist&lt;/p&gt;

&lt;p&gt;Strong Database Fundamentals+Strong Programming - Software Engineer in Machine Learning&lt;/p&gt;

&lt;p&gt;PhD in ML - All of the above + Research labs and Academia (self driving cars,ai in robotics,…)&lt;/p&gt;

&lt;p&gt;Data scientists in most companies analyze user/log data and use it to improve efficiency in various areas to boost revenue. Work could range from recommendation systems, business intelligence,data center optimization etc.. Quant Analysts try to understand the high velocity financial market data to provide better insights into investment management. Software Engineers in ML generally work on pipelines that can handle data for machine learning models on a large scale. Again, I have generalized to provide an idea of the various roles and there will be overlaps between roles and requirements for those roles.&lt;/p&gt;

&lt;p&gt;Machine learning is a trend on its own, but within it, deep learning is now more trendy. Deep Learning is nothing but huge neural networks. Neural networks are a set of layers that contain functions that transform data in each layer before passing to the next layer. These include functions such as Tanh. So in a way, deep learning is learning the best way to use bunch of Tanh functions in multiple layers that can help best correlate input to network and output from network. Sounds quite different now and that is my point. An improvement in this field and machine learning in general would require expert knowledge of mathematics in the above mentioned core areas.Also do note that if the goal is implementation of already discovered algorithms and build systems with it, understanding scalable and distributed machine learning along with some frameworks such as Apache Spark would be handy to build the next cool app.&lt;/p&gt;

&lt;p&gt;A reason for curiosity in Deep Learning is because it has been observed that these deep networks can learn representations and generalize well as seen by the famous Atari game player by DeepMind that could learn to play Atari games that it was not specifically trained for. This could potentially be very useful in the ultimate aim to create generic intelligence that learns like humans rather than intelligence for a specific problem domain that it was prepped for. The reason for the popularity in deep learning now is the low cost and also better infrastructure that can handle training these huge networks (Amazon AWS GPU Nodes) and accessibility to developers through libraries such as Theano. Machine Learning and Deep Learning are only going to grow with the continuous influx of data in various forms including computer generated data. With the popularity of sensors, this data is going to blow up. If infrastructure quality and costs can keep pace with the rise in data, we can expect more people to enter this field from various domains over the next 10-20 years which would lead to more amazing applications.&lt;/p&gt;</content><summary>In this post, I will at a high level describe this field and answer some of these questions -</summary></entry></feed>
